{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc3ac2f",
   "metadata": {},
   "source": [
    "# CogniRad++: Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use CogniRad++ for chest X-ray report generation.\n",
    "\n",
    "**Features:**\n",
    "- Load pretrained model\n",
    "- Generate structured radiology reports\n",
    "- Predict diseases with confidence scores\n",
    "- Visualize attention maps\n",
    "- Interactive clinician interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb2a9f",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from models.cognirad import CogniRadPlusPlus\n",
    "from models.classifier import CheXpertLabelEncoder\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d79c23",
   "metadata": {},
   "source": [
    "## 2. Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHECKPOINT_PATH = '../checkpoints/best_model.pt'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Loading model from: {CHECKPOINT_PATH}\")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "\n",
    "# Create model\n",
    "model = CogniRadPlusPlus(\n",
    "    visual_backbone='resnet50',\n",
    "    num_diseases=14,\n",
    "    pretrained=False\n",
    ").to(DEVICE)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538265ef",
   "metadata": {},
   "source": [
    "## 3. Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849fff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def load_and_preprocess_image(image_path: str):\n",
    "    \"\"\"Load and preprocess chest X-ray image\"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "    return img, img_tensor\n",
    "\n",
    "print(\"‚úÖ Image preprocessing ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3163c5a",
   "metadata": {},
   "source": [
    "## 4. Generate Report for Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284967fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example image path (replace with your image)\n",
    "IMAGE_PATH = '../data/example_cxr.jpg'\n",
    "CLINICAL_INDICATION = \"55M with fever and cough\"\n",
    "\n",
    "# Load image\n",
    "if os.path.exists(IMAGE_PATH):\n",
    "    original_img, img_tensor = load_and_preprocess_image(IMAGE_PATH)\n",
    "    img_tensor = img_tensor.to(DEVICE)\n",
    "    \n",
    "    # Display image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(original_img, cmap='gray')\n",
    "    plt.title('Chest X-ray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate report\n",
    "    print(\"\\nüîÑ Generating report...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        report = model.generate_report(\n",
    "            images=img_tensor,\n",
    "            clinical_indication=CLINICAL_INDICATION,\n",
    "            confidence_threshold=0.7,\n",
    "            include_evidence=True\n",
    "        )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RADIOLOGY REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nClinical Indication: {report['clinical_indication']}\")\n",
    "    print(f\"\\nFINDINGS:\\n{report['findings']}\")\n",
    "    print(f\"\\nIMPRESSION:\\n{report['impression']}\")\n",
    "    \n",
    "    # Disease predictions\n",
    "    if report['predicted_diseases']:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PREDICTED PATHOLOGIES\")\n",
    "        print(\"=\"*70)\n",
    "        for disease in report['predicted_diseases']:\n",
    "            print(f\"\\n‚Ä¢ {disease['label']}\")\n",
    "            print(f\"  Probability: {disease['probability']:.2%}\")\n",
    "            print(f\"  Confidence:  {disease['confidence']:.2%}\")\n",
    "    \n",
    "    # Warnings\n",
    "    if 'warnings' in report:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚ö†Ô∏è  WARNINGS\")\n",
    "        print(\"=\"*70)\n",
    "        for warning in report['warnings']:\n",
    "            print(f\"‚Ä¢ {warning}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Image not found: {IMAGE_PATH}\")\n",
    "    print(\"Please provide a chest X-ray image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef91f6c",
   "metadata": {},
   "source": [
    "## 5. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed453d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple images\n",
    "IMAGE_DIR = '../data/examples'\n",
    "\n",
    "if os.path.exists(IMAGE_DIR):\n",
    "    image_files = list(Path(IMAGE_DIR).glob('*.jpg')) + list(Path(IMAGE_DIR).glob('*.png'))\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images\")\n",
    "    \n",
    "    for img_path in image_files[:5]:  # Process first 5\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Processing: {img_path.name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        original_img, img_tensor = load_and_preprocess_image(str(img_path))\n",
    "        img_tensor = img_tensor.to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            report = model.generate_report(\n",
    "                images=img_tensor,\n",
    "                clinical_indication=\"Chest X-ray\"\n",
    "            )\n",
    "        \n",
    "        # Display image and report\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "        ax.imshow(original_img, cmap='gray')\n",
    "        ax.set_title(img_path.name)\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nFindings: {report['findings'][:200]}...\")\n",
    "        print(f\"\\nDiseases: {len(report['predicted_diseases'])} detected\")\n",
    "else:\n",
    "    print(f\"Directory not found: {IMAGE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac195a",
   "metadata": {},
   "source": [
    "## 6. Visualize Attention Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def visualize_attention(image, attention_map, alpha=0.5):\n",
    "    \"\"\"Overlay attention map on image\"\"\"\n",
    "    # Convert image to numpy\n",
    "    img_np = np.array(image)\n",
    "    \n",
    "    # Resize attention map to image size\n",
    "    if isinstance(attention_map, torch.Tensor):\n",
    "        attention_map = attention_map.cpu().numpy()\n",
    "    \n",
    "    # Normalize attention\n",
    "    attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min())\n",
    "    \n",
    "    # Resize to image size\n",
    "    attention_resized = cv2.resize(attention_map, (img_np.shape[1], img_np.shape[0]))\n",
    "    \n",
    "    # Apply colormap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * attention_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Overlay\n",
    "    if len(img_np.shape) == 2:\n",
    "        img_np = np.stack([img_np] * 3, axis=-1)\n",
    "    \n",
    "    overlay = cv2.addWeighted(img_np, 1-alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "# Generate report with attention\n",
    "if os.path.exists(IMAGE_PATH):\n",
    "    original_img, img_tensor = load_and_preprocess_image(IMAGE_PATH)\n",
    "    img_tensor = img_tensor.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        report = model.generate_report(\n",
    "            images=img_tensor,\n",
    "            clinical_indication=CLINICAL_INDICATION,\n",
    "            include_evidence=True\n",
    "        )\n",
    "    \n",
    "    # Visualize attention for each predicted disease\n",
    "    if 'attention_maps' in report and report['attention_maps']['concept_attention'] is not None:\n",
    "        attention = report['attention_maps']['concept_attention'][0, 0, :]  # [num_concepts]\n",
    "        \n",
    "        # Create heatmap (simplified - in production, use actual spatial attention)\n",
    "        attention_2d = attention.view(7, 7).cpu().numpy()  # Reshape to 2D\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        axes[0].imshow(original_img, cmap='gray')\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        overlay = visualize_attention(original_img, attention_2d)\n",
    "        axes[1].imshow(overlay)\n",
    "        axes[1].set_title('Attention Map')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Attention maps not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f84f42",
   "metadata": {},
   "source": [
    "## 7. Interactive Clinician Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple interactive interface\n",
    "def interactive_diagnosis(image_path: str, clinical_indication: str):\n",
    "    \"\"\"Interactive report generation\"\"\"\n",
    "    # Load and process\n",
    "    original_img, img_tensor = load_and_preprocess_image(image_path)\n",
    "    img_tensor = img_tensor.to(DEVICE)\n",
    "    \n",
    "    # Generate report\n",
    "    with torch.no_grad():\n",
    "        report = model.generate_report(\n",
    "            images=img_tensor,\n",
    "            clinical_indication=clinical_indication,\n",
    "            confidence_threshold=0.7\n",
    "        )\n",
    "    \n",
    "    # Display\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AUTOMATED RADIOLOGY REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nIndication: {clinical_indication}\")\n",
    "    print(f\"\\nFINDINGS:\\n{report['findings']}\")\n",
    "    print(f\"\\nIMPRESSION:\\n{report['impression']}\")\n",
    "    \n",
    "    # Show predictions\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PREDICTED PATHOLOGIES (>50% confidence)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for disease in report['predicted_diseases']:\n",
    "        confidence_emoji = \"üü¢\" if disease['confidence'] > 0.8 else \"üü°\"\n",
    "        print(f\"{confidence_emoji} {disease['label']}: {disease['probability']:.1%}\")\n",
    "    \n",
    "    # Uncertain findings\n",
    "    if report['uncertain_findings']:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚ö†Ô∏è  UNCERTAIN FINDINGS (require clinical correlation)\")\n",
    "        print(\"=\"*70)\n",
    "        for disease in report['uncertain_findings']:\n",
    "            print(f\"‚Ä¢ {disease['label']}: {disease['probability']:.1%} (low confidence)\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Example usage\n",
    "if os.path.exists(IMAGE_PATH):\n",
    "    report = interactive_diagnosis(\n",
    "        IMAGE_PATH,\n",
    "        \"72F presenting with shortness of breath\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a828e",
   "metadata": {},
   "source": [
    "## 8. Export Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114fa309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_report(report: dict, output_path: str):\n",
    "    \"\"\"Export report to JSON\"\"\"\n",
    "    report_data = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'clinical_indication': report['clinical_indication'],\n",
    "        'findings': report['findings'],\n",
    "        'impression': report['impression'],\n",
    "        'predicted_diseases': report['predicted_diseases'],\n",
    "        'uncertain_findings': report.get('uncertain_findings', []),\n",
    "        'warnings': report.get('warnings', [])\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(report_data, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Report exported to {output_path}\")\n",
    "\n",
    "# Example\n",
    "if 'report' in locals():\n",
    "    export_report(report, '../outputs/example_report.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058aad6",
   "metadata": {},
   "source": [
    "## 9. Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a545b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model information\n",
    "print(\"CogniRad++ Model Statistics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total Parameters:     {total_params:,} ({total_params/1e6:.2f}M)\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,} ({trainable_params/1e6:.2f}M)\")\n",
    "\n",
    "# Component breakdown\n",
    "encoder_params = sum(p.numel() for p in model.visual_encoder.parameters())\n",
    "classifier_params = sum(p.numel() for p in model.disease_classifier.parameters())\n",
    "decoder_params = sum(p.numel() for p in model.report_generator.parameters())\n",
    "\n",
    "print(f\"\\nComponent Breakdown:\")\n",
    "print(f\"  Visual Encoder:     {encoder_params:,} ({encoder_params/1e6:.2f}M)\")\n",
    "print(f\"  Disease Classifier: {classifier_params:,} ({classifier_params/1e6:.2f}M)\")\n",
    "print(f\"  Report Generator:   {decoder_params:,} ({decoder_params/1e6:.2f}M)\")\n",
    "\n",
    "# Supported diseases\n",
    "print(f\"\\nSupported Disease Labels ({model.num_diseases}):\")\n",
    "for i, label in enumerate(model.label_encoder.label_names, 1):\n",
    "    print(f\"  {i:2d}. {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5768a",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "‚úÖ Loading pretrained CogniRad++ model  \n",
    "‚úÖ Generating structured radiology reports  \n",
    "‚úÖ Disease prediction with confidence scores  \n",
    "‚úÖ Attention visualization  \n",
    "‚úÖ Interactive clinician interface  \n",
    "‚úÖ Batch processing  \n",
    "‚úÖ Report export  \n",
    "\n",
    "**Next Steps:**\n",
    "- Fine-tune on your own dataset\n",
    "- Integrate with PACS systems\n",
    "- Deploy as web service\n",
    "- Conduct clinical validation studies"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
